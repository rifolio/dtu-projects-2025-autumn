{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d652feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configure DSPy with Gemini model\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "50698135",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=api_key, cache=False)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0087dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptor(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Generate a detailed, structured description of a Star Wars (we only consider original trilogy) location/scene name using: `location_name`\n",
    "\n",
    "    Rely on established canon knowledge about original trilogy instead, consider all location within context of original trilogy. \n",
    "    Do not invent unsupported facts. Levae output as '' if you cannot find any information.\n",
    "\n",
    "    Output:\n",
    "    Summary 3–6 sentences on the location’s role, history, and significance.\n",
    "    Physical Description: key environmental or architectural traits.\n",
    "    Narrative Function: how the location is used in stories or lore.\n",
    "    Atmosphere: emotional tone and typical sentiments linked to the location.\n",
    "\n",
    "    Go right into summary, no markdown formating, only plain text.\n",
    "    Do not include \"Summary\" in the output.\n",
    "    \"\"\"\n",
    "\n",
    "    location_name: str = dspy.InputField(description=\"The name of the location to describe. This can also be a place or the scene name.\")\n",
    "    description: str = dspy.OutputField(description=\"A detailed, structured description of the location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "40e9d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = dspy.ChainOfThought(Descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f5f3c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc(location_name: str, wiki_page: str):\n",
    "    return descriptor(location_name=location_name).description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "bcdc7e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 locations to process\n",
      "First few locations: ['Another Cockpit', 'Asteroid Cave', 'Barge Observation Deck', 'Battlefield', \"Biggs' Cockpit\"]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load location_characters.json\n",
    "with open('data/location_characters.json', 'r') as f:\n",
    "    location_characters = json.load(f)\n",
    "\n",
    "# Get all location keys\n",
    "locations = list(location_characters.keys())\n",
    "print(f\"Found {len(locations)} locations to process\")\n",
    "print(f\"First few locations: {locations[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7db73373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import re\n",
    "# import time\n",
    "# from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "# import requests\n",
    "\n",
    "# API = \"https://en.wikipedia.org/w/api.php\"\n",
    "\n",
    "# NAMES = [\n",
    "#     # ... put your list here ...\n",
    "# ]\n",
    "\n",
    "# STARWARS_HINTS = [\n",
    "#     \"star wars\",\n",
    "#     \"galactic\",\n",
    "#     \"jedi\",\n",
    "#     \"sith\",\n",
    "#     \"luke\",\n",
    "#     \"leia\",\n",
    "#     \"han solo\",\n",
    "#     \"tatooine\",\n",
    "#     \"endor\",\n",
    "#     \"hoth\",\n",
    "#     \"dagobah\",\n",
    "#     \"death star\",\n",
    "# ]\n",
    "\n",
    "\n",
    "# def wiki_get(session: requests.Session, params: Dict[str, Any], timeout_s: int = 30) -> Dict[str, Any]:\n",
    "#     r = session.get(API, params=params, timeout=timeout_s)\n",
    "#     r.raise_for_status()\n",
    "#     return r.json()\n",
    "\n",
    "\n",
    "# def search(session: requests.Session, srsearch: str, limit: int = 5) -> List[Dict[str, Any]]:\n",
    "#     data = wiki_get(\n",
    "#         session,\n",
    "#         {\n",
    "#             \"action\": \"query\",\n",
    "#             \"list\": \"search\",\n",
    "#             \"srsearch\": srsearch,\n",
    "#             \"srlimit\": limit,\n",
    "#             \"srnamespace\": 0,\n",
    "#             \"format\": \"json\",\n",
    "#             \"formatversion\": 2,\n",
    "#         },\n",
    "#     )\n",
    "#     return data.get(\"query\", {}).get(\"search\", []) or []\n",
    "\n",
    "\n",
    "# def score_hit(name: str, hit: Dict[str, Any]) -> float:\n",
    "#     \"\"\"\n",
    "#     Score a search hit for being Star Wars-specific and matching the name.\n",
    "#     Uses title + snippet heuristics.\n",
    "#     \"\"\"\n",
    "#     title = (hit.get(\"title\") or \"\").lower()\n",
    "#     snippet = re.sub(r\"<.*?>\", \" \", (hit.get(\"snippet\") or \"\")).lower()\n",
    "#     text = f\"{title} {snippet}\"\n",
    "\n",
    "#     s = 0.0\n",
    "#     name_l = name.lower()\n",
    "\n",
    "#     # Name closeness\n",
    "#     if title == name_l:\n",
    "#         s += 4.0\n",
    "#     if name_l in title:\n",
    "#         s += 2.5\n",
    "#     if name_l in snippet:\n",
    "#         s += 1.0\n",
    "\n",
    "#     # Star Wars signals\n",
    "#     if \"star wars\" in text:\n",
    "#         s += 3.0\n",
    "#     for kw in STARWARS_HINTS:\n",
    "#         if kw in text:\n",
    "#             s += 0.4\n",
    "\n",
    "#     # Penalize obvious non-Star-Wars ambiguity pages\n",
    "#     if \"(disambiguation)\" in title:\n",
    "#         s -= 2.0\n",
    "\n",
    "#     # Wikipedia's own search rank (lower index is better) isn't provided directly,\n",
    "#     # but we can lightly trust 'wordcount' as a weak proxy for \"real page\".\n",
    "#     wc = hit.get(\"wordcount\") or 0\n",
    "#     s += min(1.0, wc / 2000.0)  # cap\n",
    "\n",
    "#     return s\n",
    "\n",
    "\n",
    "# def pick_best_starwars_title(session: requests.Session, name: str) -> Optional[str]:\n",
    "#     # Query variants (most targeted first)\n",
    "#     queries = [\n",
    "#         f\"\\\"{name}\\\" Star Wars\",\n",
    "#         f\"intitle:\\\"{name}\\\" Star Wars\",\n",
    "#         f\"incategory:\\\"Star Wars\\\" \\\"{name}\\\"\",\n",
    "#         f\"incategory:\\\"Star Wars\\\" {name}\",\n",
    "#         f\"{name} Star Wars\",\n",
    "#     ]\n",
    "\n",
    "#     best: Tuple[float, Optional[str]] = (-1e9, None)\n",
    "\n",
    "#     for q in queries:\n",
    "#         hits = search(session, q, limit=8)\n",
    "#         for h in hits:\n",
    "#             sc = score_hit(name, h)\n",
    "#             if sc > best[0]:\n",
    "#                 best = (sc, h.get(\"title\"))\n",
    "#         # early exit if we found a very strong match\n",
    "#         if best[0] >= 7.0:\n",
    "#             break\n",
    "\n",
    "#     return best[1]\n",
    "\n",
    "\n",
    "# def fetch_page(session: requests.Session, title: str) -> Dict[str, Any]:\n",
    "#     data = wiki_get(\n",
    "#         session,\n",
    "#         {\n",
    "#             \"action\": \"query\",\n",
    "#             \"titles\": title,\n",
    "#             \"prop\": \"extracts|info|categories|pageprops\",\n",
    "#             \"exintro\": 1,\n",
    "#             \"explaintext\": 1,\n",
    "#             \"cllimit\": 200,\n",
    "#             \"inprop\": \"url\",\n",
    "#             \"redirects\": 1,\n",
    "#             \"format\": \"json\",\n",
    "#             \"formatversion\": 2,\n",
    "#         },\n",
    "#     )\n",
    "#     pages = (data.get(\"query\", {}).get(\"pages\") or [])\n",
    "#     if not pages or not isinstance(pages[0], dict) or pages[0].get(\"missing\"):\n",
    "#         return {\"ok\": False, \"error\": {\"code\": \"missingtitle\"}, \"requested_title\": title}\n",
    "\n",
    "#     p = pages[0]\n",
    "#     return {\n",
    "#         \"ok\": True,\n",
    "#         \"title\": p.get(\"title\"),\n",
    "#         \"pageid\": p.get(\"pageid\"),\n",
    "#         \"fullurl\": p.get(\"fullurl\"),\n",
    "#         \"extract\": p.get(\"extract\") or \"\",\n",
    "#         \"categories\": [c.get(\"title\") for c in (p.get(\"categories\") or []) if isinstance(c, dict)],\n",
    "#         \"pageprops\": p.get(\"pageprops\") or {},\n",
    "#     }\n",
    "\n",
    "\n",
    "# def run(names: List[str], out_path: str = \"wikipedia_starwars_only.json\", throttle_s: float = 0.25) -> List[Dict[str, Any]]:\n",
    "#     session = requests.Session()\n",
    "#     session.headers.update(\n",
    "#         {\n",
    "#             \"User-Agent\": \"StarWarsOnlyWikiFetcher/1.0 (requests; contact: you@example.com)\",\n",
    "#             \"Accept\": \"application/json\",\n",
    "#         }\n",
    "#     )\n",
    "\n",
    "#     results: List[Dict[str, Any]] = []\n",
    "#     for i, name in enumerate(names, 1):\n",
    "#         chosen = pick_best_starwars_title(session, name)\n",
    "#         if not chosen:\n",
    "#             item = {\"ok\": False, \"requested_title\": name, \"error\": {\"code\": \"no_starwars_match\"}}\n",
    "#         else:\n",
    "#             item = fetch_page(session, chosen)\n",
    "#             item[\"requested_title\"] = name\n",
    "#             item[\"resolved_title\"] = chosen\n",
    "\n",
    "#             # Hard filter: require some Star Wars signal in categories/title/extract\n",
    "#             hay = (item.get(\"title\", \"\") + \" \" + item.get(\"extract\", \"\") + \" \" + \" \".join(item.get(\"categories\", []))).lower()\n",
    "#             if \"star wars\" not in hay and not any(k in hay for k in (\"tatooine\", \"endor\", \"hoth\", \"dagobah\", \"death star\")):\n",
    "#                 item = {\n",
    "#                     \"ok\": False,\n",
    "#                     \"requested_title\": name,\n",
    "#                     \"resolved_title\": chosen,\n",
    "#                     \"error\": {\"code\": \"resolved_but_not_starwars_enough\"},\n",
    "#                 }\n",
    "\n",
    "#         results.append(item)\n",
    "#         status = \"OK\" if item.get(\"ok\") else \"FAIL\"\n",
    "#         print(f\"[{i:>3}/{len(names)}] {status}  {name} -> {item.get('resolved_title') or item.get('error',{}).get('code')}\")\n",
    "#         time.sleep(throttle_s)\n",
    "\n",
    "#     with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "#     print(f\"\\nSaved to {out_path}\")\n",
    "#     return results\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # quick demo; replace with your full list\n",
    "#     demo = locations\n",
    "#     run(demo, out_path=\"wikipedia_starwars_only_demo.json\")\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "51237177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total locations from location_characters.json: 94\n",
      "Locations with successful wiki data: 83\n",
      "Locations missing wiki data: 11\n"
     ]
    }
   ],
   "source": [
    "# Load all locations from location_characters.json\n",
    "with open('data/location_characters.json', 'r') as f:\n",
    "    location_characters = json.load(f)\n",
    "all_locations = list(location_characters.keys())\n",
    "print(f\"Total locations from location_characters.json: {len(all_locations)}\")\n",
    "\n",
    "# Load Wikipedia scraping results\n",
    "with open('wikipedia_starwars_only_demo.json', 'r', encoding='utf-8') as f:\n",
    "    wiki_data = json.load(f)\n",
    "\n",
    "# Create a mapping of location names to their wiki extracts\n",
    "wiki_map = {}\n",
    "for entry in wiki_data:\n",
    "    location_name = entry.get('requested_title', '')\n",
    "    if entry.get('ok') and entry.get('extract'):\n",
    "        wiki_map[location_name] = entry.get('extract', '')\n",
    "    else:\n",
    "        # Mark as failed/missing\n",
    "        wiki_map[location_name] = None\n",
    "\n",
    "print(f\"Locations with successful wiki data: {sum(1 for v in wiki_map.values() if v is not None)}\")\n",
    "print(f\"Locations missing wiki data: {sum(1 for v in wiki_map.values() if v is None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "820a4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 94 dspy.Example instances (all 94 locations)\n",
      "Locations with wiki context: 83\n",
      "Locations with empty context: 11\n",
      "\n",
      "Missing locations (will use empty context):\n",
      "  - Barge Observation Deck\n",
      "  - Battlefield\n",
      "  - Bunker\n",
      "  - Dungeon Corridor\n",
      "  - Ewok Village Square\n",
      "  - Ext/Int\n",
      "  - Forest Clearing\n",
      "  - Gantry\n",
      "  - Ridge\n",
      "  - Scout Campsite\n",
      "  - Zev's Snowspeeder, Rogue Two\n",
      "\n",
      "First example:\n",
      "  Location: Another Cockpit\n",
      "  Wiki page length: 870 characters\n",
      "  Wiki page preview: Star Wars: Squadrons is a space combat game set in the Star Wars universe, developed by Motive Studio and published by Electronic Arts. It was release...\n"
     ]
    }
   ],
   "source": [
    "# Create examples for ALL 94 locations\n",
    "# Use wiki_page if available, otherwise use empty string\n",
    "examples = []\n",
    "missing_locations = []\n",
    "\n",
    "for location_name in all_locations:\n",
    "    # Get wiki_page from the map, or use empty string if not found\n",
    "    wiki_page = wiki_map.get(location_name, '')\n",
    "    if wiki_page is None:\n",
    "        wiki_page = ''  # Failed scraping, use empty context\n",
    "    \n",
    "    # Create a dspy.Example with the inputs matching the Descriptor signature\n",
    "    example = dspy.Example(\n",
    "        location_name=location_name,\n",
    "        wiki_page=wiki_page\n",
    "    ).with_inputs('location_name', 'wiki_page')\n",
    "    examples.append(example)\n",
    "    \n",
    "    if not wiki_page:\n",
    "        missing_locations.append(location_name)\n",
    "\n",
    "print(f\"Created {len(examples)} dspy.Example instances (all {len(all_locations)} locations)\")\n",
    "print(f\"Locations with wiki context: {len(examples) - len(missing_locations)}\")\n",
    "print(f\"Locations with empty context: {len(missing_locations)}\")\n",
    "if missing_locations:\n",
    "    print(f\"\\nMissing locations (will use empty context):\")\n",
    "    for loc in missing_locations:\n",
    "        print(f\"  - {loc}\")\n",
    "\n",
    "print(f\"\\nFirst example:\")\n",
    "print(f\"  Location: {examples[0].location_name}\")\n",
    "print(f\"  Wiki page length: {len(examples[0].wiki_page)} characters\")\n",
    "if examples[0].wiki_page:\n",
    "    print(f\"  Wiki page preview: {examples[0].wiki_page[:150]}...\")\n",
    "else:\n",
    "    print(f\"  Wiki page: (empty - will rely on LLM knowledge)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "36fff273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import Parallel\n",
    "\n",
    "def call_generate_desc(**kwargs):\n",
    "    \"\"\"Wrapper to call generate_desc - accepts keyword arguments from Parallel\"\"\"\n",
    "    return generate_desc(\n",
    "        location_name=kwargs.get('location_name', ''),\n",
    "        wiki_page=kwargs.get('wiki_page', '')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "35445e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_pairs = [\n",
    "    (call_generate_desc, example.inputs()) \n",
    "    for example in examples\n",
    "]\n",
    "\n",
    "# Create Parallel executor\n",
    "parallel_executor = Parallel(\n",
    "    num_threads=100,\n",
    "    max_errors=None,\n",
    "    access_examples=True,\n",
    "    return_failed_examples=False,\n",
    "    provide_traceback=True,\n",
    "    disable_progress_bar=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f96f0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 94 / 94 examples: 100%|██████████| 94/94 [00:22<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "parallel_results = parallel_executor(exec_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "58bbaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 94 location descriptions to data/location_descriptions_llm_gemini_2_5_flash.json\n"
     ]
    }
   ],
   "source": [
    "output_data = []\n",
    "for i, (example, result) in enumerate(zip(examples, parallel_results)):\n",
    "    output_data.append({\n",
    "        'location_name': example.location_name,\n",
    "        'description': result # result is the description string from generate_desc\n",
    "    })\n",
    "\n",
    "output_file = 'data/location_descriptions_llm_gemini_2_5_flash.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(output_data)} location descriptions to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ac9ce837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_token_cost(lm=lm):\n",
    "    cost = sum(x['cost'] for x in lm.history if x.get('cost') is not None)\n",
    "    total_tokens_used = sum(\n",
    "        x['usage']['total_tokens']\n",
    "        for x in lm.history\n",
    "        if x.get('usage') and x['usage'].get('total_tokens') is not None\n",
    "    )\n",
    "    print(f\"Total tokens used: {total_tokens_used}\")\n",
    "    print(f\"Total cost: ${cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1e27d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used: 134205\n",
      "Total cost: $0.258046\n"
     ]
    }
   ],
   "source": [
    "price_token_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fde2a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
