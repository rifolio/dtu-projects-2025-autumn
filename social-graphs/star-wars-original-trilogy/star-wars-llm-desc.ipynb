{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "d652feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Configure DSPy with Gemini model\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "50698135",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=api_key)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0087dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Descriptor(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Generate a detailed, structured description of a Star Wars (we only consider original trilogy) location/scene name using: `location_name` and `scene_action`.\n",
    "\n",
    "    Rely on established canon knowledge about original trilogy instead, consider all location within context of original trilogy. \n",
    "    Use the provided scene action and dialogues to understand the context, atmosphere, and events that occur at this location.\n",
    "    Do not invent unsupported facts. Leave output as '' if you cannot find any information.\n",
    "\n",
    "    Output:\n",
    "    Summary 3–6 sentences on the location’s role, history, and significance.\n",
    "    Physical Description: key environmental or architectural traits.\n",
    "    Narrative Function: how the location is used in stories or lore.\n",
    "    Atmosphere: emotional tone and typical sentiments linked to the location.\n",
    "\n",
    "    Go right into summary, no markdown formating, only plain text.\n",
    "    Do not include \"Summary\" in the output.\n",
    "    \"\"\"\n",
    "\n",
    "    location_name: str = dspy.InputField(description=\"The name of the location to describe. This can also be a place or the scene name.\")\n",
    "    scene_action: str = dspy.InputField(description=\"Action happened at this location/scene to provide context and atmosphere.\")\n",
    "    description: str = dspy.OutputField(description=\"A detailed, structured description of the location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "40e9d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor = dspy.ChainOfThought(Descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7340815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 94 locations to process\n",
      "First few locations: ['Another Cockpit', 'Asteroid Cave', 'Barge Observation Deck', 'Battlefield', \"Biggs' Cockpit\"]\n",
      "\n",
      "Extracting location content (dialogs + actions) from script files...\n",
      "Processing Star-Wars-A-New-Hope.html...\n",
      "Processing Star-Wars-The-Empire-Strikes-Back.html...\n",
      "Processing Star-Wars-Return-of-the-Jedi.html...\n",
      "Extracted content for 131 locations\n",
      "Sample locations with content: ['Rebel Blockade Runner', 'Spacecraft In Space', 'Tatooine', 'Imperial Star Destroyer', 'Lifepod']\n",
      "\n",
      "Sample content for 'Rebel Blockade Runner':\n",
      "An explosion rocks the ship as two robots, Artoo-Detoo (R2-\n",
      "D2) and See-Threepio (C-3PO) struggle to make their way\n",
      "through the shaking, bouncing passageway. Both robots are\n",
      "old and battered. Artoo is\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load location_characters.json to get all locations\n",
    "with open('data/location_characters.json', 'r') as f:\n",
    "    location_characters = json.load(f)\n",
    "\n",
    "# Get all location keys\n",
    "locations = list(location_characters.keys())\n",
    "print(f\"Found {len(locations)} locations to process\")\n",
    "print(f\"First few locations: {locations[:5]}\")\n",
    "\n",
    "# Location normalization mapping to merge redundant location names\n",
    "LOCATION_NORMALIZATION = {\n",
    "    \"Darth Vader's Star Destroyer\": \"Vader's Star Destroyer\",\n",
    "    \"Imperial Stardestroyer\": \"Imperial Star Destroyer\",\n",
    "    \"Luke's X-Wing Fighter\": \"Luke's X-Wing\",\n",
    "    \"Main Hangar Deck\": \"Main Hangar\",\n",
    "    \"Red Ten's Cockpit.\": \"Red Ten's Cockpit\",\n",
    "    \"Sail Barge Observation Deck\": \"Sail Barge\",\n",
    "    \"Snowspeeder Cockpit\": \"Snowspeeder\",\n",
    "    \"Stolen Imperial Shuttle\": \"Imperial Shuttle\",\n",
    "    \"Tatooine Sea\": \"Tatooine\",\n",
    "    \"Red Leader's X-Wing\": \"Red Leader Starship\",\n",
    "    \"Red Leader's Cockpit\": \"Red Leader Starship\",\n",
    "    \"Red Leader's Fighter\": \"Red Leader Starship\",\n",
    "    \"Read Leader's Cockpit\": \"Red Leader Starship\",\n",
    "    \"Read Leader's X-Wing Fighter\": \"Red Leader Starship\",\n",
    "}\n",
    "\n",
    "def clean_location_name(location):\n",
    "    \"\"\"Clean location name to match keys in location_characters.json\"\"\"\n",
    "    if not location:\n",
    "        return None\n",
    "    \n",
    "    # Remove scene number prefix (Return of the Jedi format: \"3    INT DEATH STAR\")\n",
    "    location = re.sub(r\"^[0-9]+\\s+\", \"\", location).strip()\n",
    "    \n",
    "    # Remove INT/EXT prefix (if present) and time of day\n",
    "    location = re.sub(r\"^(INT|EXT)[\\.\\s]+\", \"\", location, flags=re.IGNORECASE).strip()\n",
    "    location = re.sub(\n",
    "        r\"\\s+[--]\\s+(DAY|NIGHT|DAWN|DUSK|CONTINUOUS)$\",\n",
    "        \"\",\n",
    "        location,\n",
    "        flags=re.IGNORECASE,\n",
    "    )\n",
    "    \n",
    "    # Remove details in parentheses\n",
    "    location = re.sub(r\"\\s*\\([^)]*\\)\\s*$\", \"\", location)\n",
    "    \n",
    "    # Extract only the first part before the first dash to get the main location\n",
    "    if \" - \" in location or \" – \" in location:\n",
    "        location = re.split(r\"\\s+[-–]\\s+\", location)[0]\n",
    "    \n",
    "    # Clean up multiple spaces\n",
    "    location = re.sub(r\"\\s+\", \" \", location).strip()\n",
    "    \n",
    "    # Convert to title case\n",
    "    location = location.title()\n",
    "    \n",
    "    # Fix apostrophe capitalization issue (e.g., \"Luke'S\" -> \"Luke's\")\n",
    "    location = re.sub(r\"'S\\b\", \"'s\", location)\n",
    "    \n",
    "    # Apply location normalization mapping to merge redundant locations\n",
    "    if location in LOCATION_NORMALIZATION:\n",
    "        location = LOCATION_NORMALIZATION[location]\n",
    "    \n",
    "    return location if location else None\n",
    "\n",
    "# Function to extract location dialogs and actions from HTML script files\n",
    "def extract_location_content():\n",
    "    \"\"\"Extract all text content (dialogs + actions) for each location from HTML script files.\"\"\"\n",
    "    DATA_DIR = Path('data')\n",
    "    html_files = [\n",
    "        DATA_DIR / 'html' / 'Star-Wars-A-New-Hope.html',\n",
    "        DATA_DIR / 'html' / 'Star-Wars-The-Empire-Strikes-Back.html',\n",
    "        DATA_DIR / 'html' / 'Star-Wars-Return-of-the-Jedi.html'\n",
    "    ]\n",
    "    \n",
    "    location_content_map = defaultdict(list)\n",
    "    \n",
    "    for html_file in html_files:\n",
    "        if not html_file.exists():\n",
    "            print(f\"Warning: {html_file} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing {html_file.name}...\")\n",
    "        \n",
    "        with open(html_file, 'r', encoding='utf-8', errors='replace') as f:\n",
    "            soup = BeautifulSoup(f.read(), 'html.parser')\n",
    "        \n",
    "        # Find the script table (same approach as scrape notebook)\n",
    "        script_table = soup.find(\"td\", class_=\"scrtext\")\n",
    "        if not script_table:\n",
    "            print(f\"Warning: Could not find scrtext table in {html_file.name}\")\n",
    "            continue\n",
    "        \n",
    "        pre_tag = script_table.find(\"pre\")\n",
    "        if not pre_tag:\n",
    "            print(f\"Warning: Could not find pre tag in {html_file.name}\")\n",
    "            continue\n",
    "        \n",
    "        script_text = pre_tag.get_text()\n",
    "        lines = script_text.split(\"\\n\")\n",
    "        \n",
    "        current_location = None\n",
    "        current_content = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line_stripped = line.strip()\n",
    "            \n",
    "            # Detect scene headings using regex\n",
    "            # Format 1: \"INT. LOCATION\" or \"EXT. LOCATION\"\n",
    "            # Format 2: \"1    INT LOCATION\" or \"3    EXT LOCATION\" (Return of the Jedi)\n",
    "            # Format 3: \"1    SPACE\" (Return of the Jedi special)\n",
    "            is_scene_heading = False\n",
    "            \n",
    "            if re.match(r\"^[0-9]+\\s+[A-Z]\", line_stripped):\n",
    "                is_scene_heading = True\n",
    "            elif re.match(r\"^(INT|EXT)\\.\\s+\", line_stripped):\n",
    "                is_scene_heading = True\n",
    "            \n",
    "            if is_scene_heading:\n",
    "                # Save previous location's content\n",
    "                if current_location:\n",
    "                    cleaned_location = clean_location_name(current_location)\n",
    "                    if cleaned_location and current_content:\n",
    "                        # Join all content lines and add to map\n",
    "                        content_text = \"\\n\".join(current_content).strip()\n",
    "                        if content_text:\n",
    "                            location_content_map[cleaned_location].append(content_text)\n",
    "                \n",
    "                # Start new location\n",
    "                current_location = line_stripped\n",
    "                current_content = []\n",
    "            else:\n",
    "                # Add line to current location's content (if we have a location)\n",
    "                if current_location and line_stripped:\n",
    "                    current_content.append(line_stripped)\n",
    "        \n",
    "        # Don't forget the last location\n",
    "        if current_location:\n",
    "            cleaned_location = clean_location_name(current_location)\n",
    "            if cleaned_location and current_content:\n",
    "                content_text = \"\\n\".join(current_content).strip()\n",
    "                if content_text:\n",
    "                    location_content_map[cleaned_location].append(content_text)\n",
    "    \n",
    "    # Combine all content for each location (in case same location appears multiple times)\n",
    "    location_content_str = {\n",
    "        loc: \"\\n\\n\".join(content_list) if content_list else \"\"\n",
    "        for loc, content_list in location_content_map.items()\n",
    "    }\n",
    "    \n",
    "    return location_content_str\n",
    "\n",
    "# Extract content for all locations\n",
    "print(\"\\nExtracting location content (dialogs + actions) from script files...\")\n",
    "location_dialogs = extract_location_content()\n",
    "print(f\"Extracted content for {len(location_dialogs)} locations\")\n",
    "print(f\"Sample locations with content: {list(location_dialogs.keys())[:5]}\")\n",
    "\n",
    "# Show sample of content for first location\n",
    "if location_dialogs:\n",
    "    first_loc = list(location_dialogs.keys())[0]\n",
    "    sample_content = location_dialogs[first_loc][:200] if location_dialogs[first_loc] else \"\"\n",
    "    print(f\"\\nSample content for '{first_loc}':\")\n",
    "    print(sample_content + \"...\" if len(sample_content) > 200 else sample_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f5f3c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc(location_name: str, scene_dialogs: str = \"\"):\n",
    "    return descriptor(location_name=location_name, scene_action=scene_dialogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "820a4555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 94 examples with location content\n"
     ]
    }
   ],
   "source": [
    "# Create examples for ALL 94 locations\n",
    "# Include dialogs and actions for each location\n",
    "examples = []\n",
    "\n",
    "for location_name in locations:\n",
    "    # Get content (dialogs + actions) for this location (empty string if not found)\n",
    "    scene_dialogs = location_dialogs.get(location_name, \"\")\n",
    "    \n",
    "    # Create a dspy.Example with the inputs matching the Descriptor signature\n",
    "    # Note: Descriptor uses 'scene_action' but we store it as 'scene_dialogs' for clarity\n",
    "    example = dspy.Example(\n",
    "        location_name=location_name,\n",
    "        scene_action=scene_dialogs  # Map to scene_action to match Descriptor signature\n",
    "    ).with_inputs('location_name', 'scene_action')\n",
    "    examples.append(example)\n",
    "\n",
    "print(f\"Created {len(examples)} examples with location content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "36fff273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import Parallel\n",
    "\n",
    "def call_generate_desc(**kwargs):\n",
    "    \"\"\"Wrapper to call generate_desc - accepts keyword arguments from Parallel\"\"\"\n",
    "    return generate_desc(\n",
    "        location_name=kwargs.get('location_name', ''),\n",
    "        scene_dialogs=kwargs.get('scene_action', '')  # Map from scene_action to scene_dialogs parameter\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "35445e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_pairs = [\n",
    "    (call_generate_desc, example.inputs()) \n",
    "    for example in examples\n",
    "]\n",
    "\n",
    "# Create Parallel executor\n",
    "parallel_executor = Parallel(\n",
    "    num_threads=100,\n",
    "    max_errors=None,\n",
    "    access_examples=True,\n",
    "    return_failed_examples=False,\n",
    "    provide_traceback=True,\n",
    "    disable_progress_bar=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "f96f0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 94 / 94 examples: 100%|██████████| 94/94 [00:35<00:00,  2.64it/s]\n"
     ]
    }
   ],
   "source": [
    "parallel_results = parallel_executor(exec_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "58bbaf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 94 location descriptions with reasoning to data/location_descriptions_llm_withSceneAction_gemini_2_5_flash.json\n"
     ]
    }
   ],
   "source": [
    "output_data = []\n",
    "for i, (example, result) in enumerate(zip(examples, parallel_results)):\n",
    "    # result is the full prediction object from generate_desc\n",
    "    # Access description and reasoning from the prediction object\n",
    "    output_data.append({\n",
    "        'location_name': example.location_name,\n",
    "        'description': result.description if hasattr(result, 'description') else '',\n",
    "        'reasoning': result.reasoning if hasattr(result, 'reasoning') else ''\n",
    "    })\n",
    "\n",
    "output_file = 'data/location_descriptions_llm_withSceneAction_gemini_2_5_flash.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(output_data)} location descriptions with reasoning to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ac9ce837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_token_cost(lm=lm):\n",
    "    cost = sum(x['cost'] for x in lm.history if x.get('cost') is not None)\n",
    "    total_tokens_used = sum(\n",
    "        x['usage']['total_tokens']\n",
    "        for x in lm.history\n",
    "        if x.get('usage') and x['usage'].get('total_tokens') is not None\n",
    "    )\n",
    "    print(f\"Total tokens used: {total_tokens_used}\")\n",
    "    print(f\"Total cost: ${cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1e27d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens used: 321642\n",
      "Total cost: $0.412415\n"
     ]
    }
   ],
   "source": [
    "price_token_cost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a802d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
